{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad20128-6945-4cf2-bc28-d1532f96a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import re\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d6b786-695d-4edd-9f78-2b0f6ffb0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sam_to_dataframe(sam_file):\n",
    "    '''\n",
    "    This function takes a SAM file to organizes the information into a DataFrame\n",
    "    \n",
    "    Input: SAM file from STAR aligment SAM stands for Sequence Alignment/Map format\n",
    "    It is a TAB-delimited text format consisting of a header section and an alignment section\n",
    "    \n",
    "    Output: DataFrame of STAR alignment information\n",
    "    '''\n",
    "    \n",
    "    # List to hold the parsed data\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Open the SAM file\n",
    "    \n",
    "    with open(sam_file, 'r') as file:\n",
    "        for line in file:\n",
    "            \n",
    "            # Skip header lines that start with '@'\n",
    "            \n",
    "            if not line.startswith('@'):\n",
    "            \n",
    "                # Split the line into columns based on tab delimiters\n",
    "                \n",
    "                columns = line.strip().split('\\t')\n",
    "                \n",
    "                # Append the columns to the data list\n",
    "                data.append(columns)\n",
    "            \n",
    "    # Define the SAM file columns (based on SAM format specification)\n",
    "            \n",
    "    columns = ['QNAME', 'FLAG', 'RNAME', 'POS', 'MAPQ', 'CIGAR', \n",
    "               'RNEXT','PNEXT', 'TLEN', 'SEQ', 'QUAL', 'Number of Hits', \n",
    "               'Hit Index','Alignment Score', 'Number of Mismatches']\n",
    "            \n",
    "    # Create a DataFrame from the data list\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fe3254-b859-4164-871f-0d4bf3ccd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_length(cigar):\n",
    "    '''\n",
    "    This function takes the CIGAR string and returns the length of the read aligment to the gene scaffold\n",
    "    \n",
    "    Input: CIGAR (Compact Idiosyncratic Gapped Alignment Report) string\n",
    "           CIGAR is how the SAM/BAM format represents spliced alignments\n",
    "           Example CIGAR code: \"10M1I5M2D8M5S\" where\n",
    "               10M = 10 bases match the reference sequence\n",
    "               1I =  1 base is inserted in the read (compared to the reference).\n",
    "               5M =  5 bases match the reference.\n",
    "               2D =  2 bases are deleted from the read (compared to the reference).\n",
    "               8M =  8 bases match the reference.\n",
    "               5S =  5 soft-clipped bases at the end of the read that do not align with the reference\n",
    "    \n",
    "    Output: Length of read that aligns to the gene scaffold\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Regular expression to find all occurrences of numbers followed by letters\n",
    "    \n",
    "    pattern = re.compile(r'(\\d+)([MIDNSHP=XB])')\n",
    "    \n",
    "    length = 0\n",
    "    \n",
    "    for count, op in pattern.findall(cigar):\n",
    "        \n",
    "        count = int(count)\n",
    "        \n",
    "        if op in ['M', 'D', 'N', '=', 'X']: # Operations that consume reference\n",
    "            length += count\n",
    "            \n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e1f509-3063-4d2f-a2f8-4bca02714976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_alignment_positions(df):\n",
    "    '''\n",
    "    This function takes the SAM DataFrame and returns an updated DataFrame with new columns\n",
    "    \n",
    "    Input: SAM DataFrame\n",
    "    \n",
    "    Output: DataFrame columns for \n",
    "        'Alignment_Length' - the length of the read that aligns to the reference gene\n",
    "        'Start_Position' - where the read starts it's alignment in the reference gene\n",
    "        'End_Position' - where the read ends it's alignment in the reference gene\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Map your columns appropriately\n",
    "    pos_column = 'POS' # POS column\n",
    "    cigar_column = 'CIGAR' # CIGAR column\n",
    "    \n",
    "    # Convert POS to integer\n",
    "    df[pos_column] = df[pos_column].astype(int)\n",
    "    \n",
    "    # Calculate alignment length and end positions\n",
    "    df['Alignment_Length'] = df[cigar_column].apply(calculate_alignment_length)\n",
    "    df['Start_Position'] = df[pos_column]\n",
    "    df['End_Position'] = df['Start_Position'] + df['Alignment_Length']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b81576c-71a6-4887-b330-1abec5f98600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the SAM file\n",
    "variable_name = 'LMH_1'\n",
    "sam_file = f'DataDrop_for_LMH_20240830_Novaseq_run/{variable_name}/{variable_name}_PEAR_Aligned.out.sam'\n",
    "\n",
    "# Parse the SAM file and create a DataFrame\n",
    "sam_df = parse_sam_to_dataframe(sam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae24f630-0638-45de-b9ef-f58809df96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'POS' (read alignment start position) column as an integer\n",
    "# Check if read alignment starts within the first 10 nts of the reference gene\n",
    "# Make new dataframe\n",
    "sam_df = sam_df[sam_df['POS'].astype(int) < 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8288375-eccb-449d-ae50-0ef71aae52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds three columns to sam_df that include information about the read alignment length and start (should match POS)/ end positions\n",
    "sam_df_with_positions = add_alignment_positions(sam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94781214-952b-44af-acc9-8fa99afbf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the aligned reads by the reference gene\n",
    "# From each read, aquire where the read ends in the alignment, 'End_Position'\n",
    "# Create a list for each reference gene of all the read end positions\n",
    "# Sort list in ascending order\n",
    "# Reset the index because .groupby() creates a new index based on the grouping\n",
    "read_lengths = sam_df_with_positions.groupby('RNAME')['End_Position'].apply(lambda x: sorted(list(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b41941-68f5-410c-9453-708e50b05871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import oligo pool sequence order form as DataFrame\n",
    "# Headers: Accession, Start, Stop, Sequence, Extended Sequences, Strand, Twist Prepped Sequence, Twist Length\n",
    "order_form = pd.read_excel('20240408_Twist_Order.xlsx')\n",
    "\n",
    "# Create column that matches the RNAME in \"result\"\n",
    "order_form['RNAME'] = order_form['Accession']+'/'+order_form['Start'].astype(str)+'-'+order_form['Stop'].astype(str)\n",
    "\n",
    "# Remove '>' character \n",
    "order_form['RNAME'] = order_form['RNAME'].str[1:]\n",
    "\n",
    "# Apply the alignment length information to each variant (RNAME) as a new column\n",
    "order_form[f'{variable_name}_Read_Lengths'] = order_form.apply(\n",
    "    lambda row: read_lengths.set_index('RNAME')['End_Position'].get(row['RNAME'], [0]), axis=1).fillna(0)\n",
    "order_form = order_form.rename(columns={'RNAME': 'Accession/Start-Stop'})\n",
    "order_form = order_form.sort_values('Accession/Start-Stop')\n",
    "\n",
    "# Count reads for each variant\n",
    "order_form[f'{variable_name}_Read_Count'] = order_form[f'{variable_name}_Read_Lengths'].apply(lambda x: len(x) if isinstance(x, (list, str)) else 0)\n",
    "\n",
    "# Classify reads as 'Terminated' with BacTermFinder probabilities\n",
    "BacTermFinder_df = pd.read_excel('Predicted_Termination.xlsx')\n",
    "\n",
    "# Drop other result columns\n",
    "BacTermFinder_df = BacTermFinder_df.drop(columns=['ARNold Results', 'Stem', 'Loops', 'iTerm windows, probability, sequence'])\n",
    "\n",
    "# Combine order_form with BacTermFinder results\n",
    "results_df = pd.merge(order_form, BacTermFinder_df, how='inner', on='Accession/Start-Stop')\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df88e27d-c751-4612-bde8-fbed19bc446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify reads as \"Terminated\"\n",
    "\n",
    "# Initialize an empty list to store the values from the 'Extended Sequences'\n",
    "Terminated_Count_List = []\n",
    "Terminated_Lengths_List =[]\n",
    "FASTA_Accession = []\n",
    "FASTA_Sequence = []\n",
    "AntiTerminated_List =[]\n",
    "\n",
    "# Loop over the DataFrame and collect read lengths\n",
    "for index, row in results_df.iterrows():\n",
    "\n",
    "    Terminated_Reads = 0\n",
    "    Termianted_Read_Count = 0\n",
    "    Terminated_Lengths = []\n",
    "    AntiTerminated_Lengths = []\n",
    "\n",
    "    read_lengths = row[f'{variable_name}_Read_Lengths']\n",
    "    \n",
    "    if read_lengths == 0:\n",
    "        Terminated_Count_List.append(Termianted_Read_Count)\n",
    "        continue\n",
    "    \n",
    "    #aptamer_length = row['Aptamer_Length']\n",
    "    ref_seq = row['Twist Prepped Sequence'][60:] #Remove J23119 promoter\n",
    "    top_score = row['BacTermFinder top_score']",
    "\n",
    "    if 0.47 < top_score: # Threshold set by BacTermFinder README recommendation\n",
    "        term_windows_scores = ast.literal_eval(row['BacTermFinder Terminator windows (start-stop), score'])\n",
    "        term_window = term_windows_scores[0]  # Get first terminator data\n",
    "        start, stop = map(int, term_window[0].split('-'))\n",
    "        # BacTermFinder 'Terminator sequences collection' method: \n",
    "        # '...we extracted the genomic sequences corresponding to 100 nt flanking the TTSs (50 nt on either side) into a FASTA file.'\n",
    "        termination_site_start = start+40\n",
    "        termination_site_stop = stop-45\n",
    "\n",
    "        # Count the alignment lengths at the Termination site\n",
    "        Terminated_Reads = [num for num in read_lengths if termination_site_start <= num <= termination_site_stop]\n",
    "        Termianted_Read_Count = len(Terminated_Reads)\n",
    "\n",
    "        ##Prepare list for FASTA file output\n",
    "        for length in Terminated_Reads:\n",
    "          FASTA_Accession.append(row['Accession/Start-Stop'])\n",
    "          FASTA_Sequence.append(ref_seq[:termination_site_stop])\n",
    "          Terminated_Lengths.append(length)\n",
    "\n",
    "        # Identify Anti-terminator count    \n",
    "\n",
    "        AntiTerminated_Lengths = [num for num in read_lengths if termination_site_stop <= num]\n",
    "    \n",
    "    # If no possible terminator sequences are identified, then save read lengths post-aptamer as Anti-Terminated\n",
    "    else:\n",
    "        apt_length = len(row['Sequence'])\n",
    "        AntiTerminated_Lengths = [num for num in read_lengths if apt_length <= num]\n",
    "            \n",
    "    Terminated_Count_List.append(Termianted_Read_Count)\n",
    "    Terminated_Lengths_List.append(Terminated_Lengths)\n",
    "    AntiTerminated_List.append(AntiTerminated_Lengths)\n",
    "\n",
    "# Add new column to DataFrame with the termination classification\n",
    "results_df[f'{variable_name}_Terminated_Lengths'] = Terminated_Lengths_List\n",
    "results_df[f'{variable_name}_Terminated_Count'] = Terminated_Count_List\n",
    "results_df[f'{variable_name}_AntiTerminated_Lengths'] = AntiTerminated_List\n",
    "results_df[f'{variable_name}_AntiTerminator_Count'] = order_form[f'{variable_name}_AntiTerminated_Lengths'].apply(lambda x: len(x) if isinstance(x, (list, str)) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066a968c-e7dd-4f54-8b1e-9f6864315718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "order_form.to_csv(f'{variable_name}_Read_Analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72dbf9af-345e-4de2-836a-62212b62a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a FASTA file of the terminated sequences to run covariation\n",
    "\n",
    "# Create a DataFrame from the two lists\n",
    "FASTA_df = pd.DataFrame({'Accession': FASTA_Accession, 'Sequence': FASTA_Sequence})\n",
    "\n",
    "# Count occurrences of each Accession\n",
    "accession_counts = FASTA_df['Accession'].value_counts()\n",
    "\n",
    "# Add a new column to store the length of values in 'Seq_length'\n",
    "FASTA_df['Seq_length'] = FASTA_df['Sequence'].apply(len)\n",
    "\n",
    "# Find the most frequent Seq_length for each Accession as a way of saving the sequence for R-scape analysis\n",
    "most_frequent_seq_length = FASTA_df.groupby('Accession')['Seq_length'].agg(lambda x: x.mode().iloc[0])\n",
    "\n",
    "# Merge back with the original dataframe to keep only rows with the most frequent Seq_length for each Accession\n",
    "FASTA_df = FASTA_df[FASTA_df['Seq_length'].isin(most_frequent_seq_length.values)]\n",
    "\n",
    "# Drop duplicates in 'Accession', keeping the first occurrence based on the most frequent Seq_length\n",
    "FASTA_df = FASTA_df.drop_duplicates(subset='Accession', keep='first')\n",
    "\n",
    "# Go through DataFrame and calculate how many fluoride riboswitches underwent transcription termination\n",
    "output_filename = f'{variable_name}_Measured_Terminators.fasta'\n",
    "\n",
    "with open(output_filename,'w') as f:\n",
    "    for index, row in FASTA_df.iterrows():\n",
    "        Name = '>'+row['Accession']\n",
    "        Sequence = row['Sequence']\n",
    "        f.write(str(Name)+'\\n'+str(Sequence)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bab4a2-02f6-45c1-b3ce-4b42df336629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
