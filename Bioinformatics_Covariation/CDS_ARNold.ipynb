{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630c5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Install Selenium and chromedriver binary\n",
    "\n",
    "import chromedriver_binary\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set chromedriver-binary version\n",
    "\n",
    "!{sys.executable} -m pip install selenium chromedriver-binary==127.0.6533.119\n",
    "#!{sys.executable} -m pip install --upgrade --force-reinstall chromedriver-binary-auto\n",
    "\n",
    "# Set chrome_options\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# Get the current working directory\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8809f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runARNold(file_path):\n",
    "    \n",
    "    '''\n",
    "    This function takes a FASTA file and sends it to the ARNold webserver then retrives and organizes the results. \n",
    "    \n",
    "    Input: file path to FASTA file of extended Rfam entries\n",
    "    \n",
    "    Output:\n",
    "        results = DataFrame of ARNold output for predicted intrinsic terminators\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Opens a Chrome window (headless)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Opens ARNOLD website on Chrome window\n",
    "    driver.get('http://rssf.i2bc.paris-saclay.fr/toolbox/arnold/index.php')\n",
    "\n",
    "    #Changes 'Search Strand' from 'Both' to 'Forward'\n",
    "    strand = driver.find_element(By.ID, '5prime')\n",
    "    strand.click()\n",
    "    \n",
    "    # Finds submit/'Run' button\n",
    "    submit = driver.find_element(By.NAME, 'Run')\n",
    "\n",
    "    # Finds button to upload input file\n",
    "    file = driver.find_element(By.NAME, 'TTPfile')\n",
    "\n",
    "    # Upload file\n",
    "    file.send_keys(file_path)\n",
    "\n",
    "    # Click submit\n",
    "    submit.click()\n",
    "\n",
    "    # Save results\n",
    "    results = driver.find_element(By.XPATH, \"//div[@id='content']/fieldset/span\").text\n",
    "    results = [x for x in results.split('\\n')]\n",
    "    \n",
    "    element = driver.find_element(By.XPATH, \"//div[@id='content']/fieldset/span\")\n",
    "    html_content = element.get_attribute('innerHTML')\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Extract sequences and their corresponding blue and red span\n",
    "    result_hairpins = []\n",
    "    panel = []\n",
    "    \n",
    "    for line in soup.prettify().split('<br>'):\n",
    "        # Clean up the line\n",
    "        line = re.sub(r'[\\n\\s]+', ' ', line).strip()\n",
    "        panel = line.split('&gt')\n",
    "\n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Extract sequence identifier\n",
    "        for item in panel:\n",
    "            match = re.match(r';(\\S+),(\\d+)', item)\n",
    "            if match:\n",
    "                seq_id = match.group(1)\n",
    "                position = match.group(2)\n",
    "                result = {\"sequence_id\": seq_id, \"position\": position, \"blue\": [], \"red\": []}\n",
    "                result_hairpins.append(result)\n",
    "            soup_line = BeautifulSoup(item, 'html.parser')\n",
    "            blue_texts = [span.text for span in soup_line.find_all('span', style=\"color: blue;\")]\n",
    "            red_texts = [span.text for span in soup_line.find_all('span', style=\"color: red;\")]\n",
    "            if blue_texts or red_texts:\n",
    "                result_hairpins[-1][\"blue\"].extend(blue_texts)\n",
    "                result_hairpins[-1][\"red\"].append(red_texts)\n",
    "          \n",
    "    # Close Chrome window\n",
    "    driver.quit()\n",
    "    \n",
    "    #finding sequences with dual terminator hits\n",
    "    for i in range(0, len(results)): #go through list\n",
    "         if re.match('   ', results[i]) != None: #identify sequences\n",
    "                if re.match('>', results[i+2]) == None: #identify duplicated sequence\n",
    "                    results.insert(i+1, \"\")\n",
    "                    species = results[i-1]\n",
    "                    results.insert(i+2, species) #give second terminator the same accession number\n",
    "\n",
    "    return results, result_hairpins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4894fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Excel of extended fluoride sequences with their coding region as a DataFrame\n",
    "\n",
    "df = pd.read_excel('Fluoride_CDS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4fdb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn DataFrame into FASTA file to send to ARNold\n",
    "\n",
    "with open('ARNold_Submit.fasta', 'w') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write('>'+row['Accession']+','+str(row['Start'])+'\\n'+row['Extended Sequences']+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51883cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn DataFrame into FASTA file for downstream R-Scape cmsearch\n",
    "\n",
    "# Remove duplicate entries that'll cause R-scape issues\n",
    "\n",
    "df = df.drop_duplicates(subset=['Accession'], keep='first')\n",
    "\n",
    "with open('Fluoride_extended.fasta', 'w') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write('>'+row['Accession']+'\\n'+row['Extended Sequences']+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32646118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your FASTA file that ARNold will accept\n",
    "\n",
    "fasta_file_path = 'ARNold_Submit.fasta'\n",
    "absolute_path = os.path.abspath(fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3764b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FASTA file through ARNold\n",
    "\n",
    "ARNold_results, ARNold_hairpins = runARNold(absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from ARNold results\n",
    "\n",
    "ARNold_df = pd.DataFrame(ARNold_hairpins)\n",
    "\n",
    "# Add a character or string to each entry in the 'sequence_id' column\n",
    "\n",
    "ARNold_df['sequence_id'] = ARNold_df['sequence_id'].apply(lambda x: \">\" + x)\n",
    "\n",
    "# Rename columns\n",
    "\n",
    "ARNold_df = ARNold_df.rename(columns={\n",
    "    \"sequence_id\": \"Accession\",\n",
    "    \"position\": \"Start\",\n",
    "    \"blue\": \"Stem\",\n",
    "    \"red\": \"Loops\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame that can be combined with the active information collection\n",
    "\n",
    "accession_list = []\n",
    "region_start_list = []\n",
    "ARNold_result_list = []\n",
    "\n",
    "current_accession = None\n",
    "accession = ''\n",
    "\n",
    "for line in ARNold_results:\n",
    "    if len(line) > 0:\n",
    "        if re.search('>', line) != None:\n",
    "            line = line.split(',')\n",
    "            accession = line[0]\n",
    "            current_accession = accession\n",
    "            accession_list.append(accession)\n",
    "            region_start_list.append(line[1]) \n",
    "        else:\n",
    "            if current_accession == accession:\n",
    "                if re.search('Total number', line) == None:\n",
    "                    ARNold_result_list.append(line)\n",
    "                    accession = None\n",
    "            else:\n",
    "                print(line)\n",
    "            \n",
    "ARNold_All_df = pd.DataFrame({'Accession': accession_list,\n 'Start': region_start_list,\n 'ARNold Results': ARNold_result_list}) #subtract the last line item of totalling the terminators\n",
    "#ARNold_All_df['Start'] = ARNold_All_df['Start'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on the 'ID' column\n",
    "\n",
    "merged_df = pd.merge(ARNold_All_df, ARNold_df, on=['Accession','Start'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list \n",
    "\n",
    "fasta_data = []\n",
    "\n",
    "# Open FASTA file of terminators\n",
    "\n",
    "fasta_file = open(fasta_file_path, 'r')\n",
    "\n",
    "# Convert FASTA file into DateFrame\n",
    "\n",
    "records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "\n",
    "for record in records:\n",
    "    \n",
    "    # Split the sequence ID into Accession and Start\n",
    "    \n",
    "    sequence_id = record.id.split(',')[0]\n",
    "    sequence_id = '>' + sequence_id\n",
    "    sequence_suffix = record.id.split(',')[1]\n",
    "    \n",
    "    # Append the sequence ID and sequence to the list\n",
    "    \n",
    "    fasta_data.append([sequence_id, sequence_suffix, str(record.seq)])\n",
    "\n",
    "fasta_df = pd.DataFrame(fasta_data, columns=[\"Accession\", 'Start', \"Full Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16881a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on the 'ID' column\n",
    "\n",
    "merged_2_df = pd.merge(fasta_df, merged_df, on=['Accession','Start'], how='inner')\n",
    "\n",
    "# Drop NaN rows\n",
    "\n",
    "merged_2_df = merged_2_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrames to excel\n",
    "\n",
    "merged_2_df.to_excel('Fluoride_CDS_ARNold.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc60c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FASTA file of predicted terminators to create alignment for R-scape\n",
    "\n",
    "merged_2_df = merged_2_df.drop_duplicates(subset=['Accession'], keep='first')\n",
    "\n",
    "with open('ARNold_Fluoride_terminators.fasta','w') as f:\n",
    "    for index, row in merged_2_df.iterrows():\n",
    "        ARNold_result = row['ARNold Results']\n",
    "        if ARNold_result != 'No predicted transcription terminator. ':\n",
    "            result = ARNold_result.split(' ')\n",
    "            result = [item for item in result if item]\n",
    "            full_sequence = row['Full Sequence']\n",
    "            stems = row['Stem']\n",
    "            loops = row['Loops']\n",
    "            loop = loops[0][0]\n",
    "            pre_polyU = stems[1]\n",
    "            terminator_start = int(result[0])\n",
    "            terminator_end = len(result[3])\n",
    "            riboswitch_length = terminator_start + terminator_end\n",
    "            terminator = full_sequence[:riboswitch_length]\n",
    "            term_len = len(terminator)\n",
    "            if 90 < term_len < 110: # By limiting sequences on length, the alignment will be cleaner\n",
    "                f.write(row['Accession']+'\\n'+terminator+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb0d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
